# Хранение больших данных

## MapReduce алгоритмы

### [Поиск наибольшего числа](./a/)

Алгоритм делится на два этапа:  
1. В начале добавляем к каждому входному значению ключ **<partition_id>**,
    по которому данные распределятся по разным reducer'ам.
    Reducer ищет локальный максимум и выводит только его;
2. К каждому локальному максимуму добавляется ключ **max**,
    чтобы все значения попали в один reducer, который все также
    ищет максимум из входных данных - глобальный максимум.


---
### [Поиск среднего арифметического всех чисел](./b/)

Алгоритм делится на два этапа:  
1. В начале добавляем к каждому входному значению ключ **<partition_id>**,
    по которому данные распределятся по разным reducer'ам.
    Reducer считает частичную сумму и количество элементов;
2. К каждой строке добавляется ключ **avg**, чтобы все значения
    попали в один reducer, который суммирует все частичные суммы
    и количества, после чего выводит ```total_sum / total_count```


---
### [Создание набора без дубликатов](./c/)

Алгоритм делится на два этапа:  
1. В начале добавляем к каждому входному значению ключ, равный самому числу,
    чтобы одни и те же числа попали в один reducer.
    Reducer выводит число на каждую непохожую запись,
    то есть одну запись без дубликатов;
2. К каждой строке добавляется ключ **unique**, чтобы все значения
    попали в один reducer, который также выводит число на каждую непохожую
    запись, а после первой стадии остались только уникальные записи.


---
### [Подсчет различных чисел во входном наборе](./d/)

Алгоритм делится на два этапа:  
1. В начале просто возвращаем число, которое и будет является ключом,
    чтобы одни и те же числа попали в один reducer.
    Reducer выводит **count** на каждую непохожую запись, то есть одну запись;
2. Строки возвращаются без изменений (count просто) и попадают в один reducer.
    Reducer считает количество входных записей, что соответствует количеству
    различных чисел во входном наборе, и выводит это число.


## Особенности хранения ОБФЦЧ

1. **Распределенное хранение**  
    Так как файл очень большой, их стоит хранить распределенно в соответствующих
    файловых системах. Файл разбивается на блоки фиксированных размеров,
    которые могут храниться в разных узлах.

2. **Восстановление данных при чтении**  
    Подобные файлы стоит хранить блоками, то должна быть возможность
    восстанавливать эти данные при чтении, так как не факт, что граница
    блока совпадет с логической границей данных.

3. **Представление данных**  
    Данные можно хранить как в текстовом формате, что упрощает их понимание,
    обработку и делает более устойчивыми к разбиению, но занимает больше места,
    так и в двоичном, что может существенно сократить размер и скорость чтения,
    но требует дополнительных обработок и внимания к границам блоков.

4. **Реплики**
    Большие файлы сложно восстановить, поэтому может быть важно хранить их копии
    на разных узлах, что повышает отказоустойчивость, безопасность и может
    повысить доступность.

5. **Последовательный доступ**
    MapReduce предполагает однократное последовательное чтение. Кроме того,
    данные гораздо чаще читаются, дописываются, чем модифицируются,
    оыбчно исходные даннные неизменны, поэтому оптимизированны
    для подобных сценариев и предназначены для пакетной обработки.

6. **Масштабируемость**
    Должна сохраняться возможность добавления новых узлов и перераспределения
    данных. Возможность обработки данных до петабайта.

Еще можно выделить отсутствие оптимизаций чтения наподобии индексов в СУБД,
так как индексировать такие объемы неразумно. Отсутствуют блокировки чтения,
транзакции, то есь файл считается неизменяемым или изменения не окажут
существенного влияния.
