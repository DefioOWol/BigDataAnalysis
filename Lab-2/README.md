# Хранение больших данных

## MapReduce алгоритмы

Далее кратко описаны алгоритмы решения задач. Каждый из них
разработан независимо, поэтому в файлах могут присутствовать дублирования
кода и описаний. Более подробное описание доступно в docstring самих
функций.

Общие элементы:
- **mapper** - функция, получающая на вход данные из файла(-ов)
    и преобразующая (сопоставляющая) их для дальнейшей обработки.
    Если фаз (этапов) в алгоритме несколько, то mapper первой фазы
    предназначен в общем случае для валидации входных данных и предоставлении
    ключей для распределения по reducer'ам для параллельной обработки.
    Во второй фазе данные обычно просто считываются и передаются дальше
    с добавлением единого ключа. Таким образом для первой фазы на вход
    подается один файл, тогда как на вход второй - директория,
    полученная после первой фазы;

- **reducer** - функция, производящая вычисления, требуемые по задаче
    (формирование выходного набора).
    При выполнении были предприняты попытки по возможности сделать
    общий reducer для обеих фаз, логика которого зависит от входных
    данных. Reducer не добавляет самостоятельно ключи, так как его выход
    напрямую пишется в файл, что для очень больших файлов значительно
    увеличило бы объем хранения. Каждый reducer пишет данные в свой файл,
    поэтому если данные распределены по разным ключам, то на выходе
    получим директорию файлов.


---
### [Поиск наибольшего числа](./a/)

Алгоритм делится на два этапа:  
1. В начале добавляем к каждому входному значению ключ **<partition_id>**,
    по которому данные распределятся по разным reducer'ам.
    Reducer ищет локальный максимум и выводит только его;
2. К каждому локальному максимуму добавляется ключ **max**,
    чтобы все значения попали в один reducer, который все также
    ищет максимум из входных данных - глобальный максимум.


---
### [Поиск среднего арифметического всех чисел](./b/)

Алгоритм делится на два этапа:  
1. В начале добавляем к каждому входному значению ключ **<partition_id>**,
    по которому данные распределятся по разным reducer'ам.
    Reducer считает частичную сумму и количество элементов;
2. К каждой строке добавляется ключ **avg**, чтобы все значения
    попали в один reducer, который суммирует все частичные суммы
    и количества, после чего выводит ```total_sum / total_count```


---
### [Создание набора без дубликатов](./c/)

Алгоритм делится на два этапа:  
1. В начале добавляем к каждому входному значению ключ, равный самому числу,
    чтобы одни и те же числа попали в один reducer.
    Reducer выводит число на каждую непохожую запись,
    то есть одну запись без дубликатов;
2. К каждой строке добавляется ключ **unique**, чтобы все значения
    попали в один reducer, который также выводит число на каждую непохожую
    запись, а после первой стадии остались только уникальные записи.


---
### [Подсчет различных чисел во входном наборе](./d/)

Алгоритм делится на два этапа:  
1. В начале просто возвращаем число, которое и будет является ключом,
    чтобы одни и те же числа попали в один reducer.
    Reducer выводит **count** на каждую непохожую запись, то есть одну запись;
2. Строки возвращаются без изменений (count просто) и попадают в один reducer.
    Reducer считает количество входных записей, что соответствует количеству
    различных чисел во входном наборе, и выводит это число.


## Особенности хранения ОБФЦЧ

1. **Распределенное хранение**  
    Так как файл очень большой, их стоит хранить распределенно в соответствующих
    файловых системах. Файл разбивается на блоки фиксированных размеров,
    которые могут храниться в разных узлах.

2. **Восстановление данных при чтении**  
    Подобные файлы стоит хранить блоками, то должна быть возможность
    восстанавливать эти данные при чтении, так как не факт, что граница
    блока совпадет с логической границей данных.

3. **Представление данных**  
    Данные можно хранить как в текстовом формате, что упрощает их понимание,
    обработку и делает более устойчивыми к разбиению, но занимает больше места,
    так и в двоичном, что может существенно сократить размер и скорость чтения,
    но требует дополнительных обработок и внимания к границам блоков.

4. **Реплики**
    Большие файлы сложно восстановить, поэтому может быть важно хранить их копии
    на разных узлах, что повышает отказоустойчивость, безопасность и может
    повысить доступность.

5. **Последовательный доступ**
    MapReduce предполагает однократное последовательное чтение. Кроме того,
    данные гораздо чаще читаются, дописываются, чем модифицируются,
    обычно исходные данные неизменны, поэтому оптимизированны
    для подобных сценариев и предназначены для пакетной обработки.

6. **Масштабируемость**
    Должна сохраняться возможность добавления новых узлов и перераспределения
    данных. Возможность обработки данных до петабайта.

Еще можно выделить отсутствие оптимизаций чтения наподобии индексов в СУБД,
так как индексировать такие объемы неразумно. Отсутствуют блокировки чтения,
транзакции, то есть файл считается неизменяемым или изменения не окажут
существенного влияния.
